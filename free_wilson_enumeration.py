#!/usr/bin/env python

import sys
import re
from collections import OrderedDict
from itertools import product
from typing import Tuple, List

import numpy as np
import pandas as pd
from pyfancy import pyfancy
from rdkit import Chem
from sklearn.externals import joblib
from tqdm import tqdm

from free_wilson_utils import reflect_rgroups, weld_r_groups


def read_input(model_file_name: str, vector_file_name: str) -> Tuple[object, object]:
    """
    Read in molecule file and pickled linear model
    @param model_file_name: name of the pickled linear model
    @param vector_file_name: name of the descriptor vector file
    @return: model and descriptor data frame
    """
    lm = joblib.load(model_file_name)
    df = pd.read_csv(vector_file_name)
    return lm, df


def parse_rgroups(df: pd.DataFrame) -> Tuple[set,list]:
    """
    Read the descriptor dataframe and identify unique R-groups
    @param df: descriptor data frame
    @return: dictionary of combinations that have already been used, summary of R-groups
    """
    # set up a regular expression to identify R-groups
    rgroup_re = re.compile("\[\*:[0-9]+\]")
    used = set()
    for row in df.values.tolist():
        used.add(",".join([str(x) for x in row[1:]]))
    # split the R-groups into R1, R2, etc
    r_group_list = list(df.columns[1:])
    r_groups = [rgroup_re.findall(x)[0] for x in r_group_list]
    r_groups = list(OrderedDict.fromkeys(r_groups))
    r_group_summary = []
    for r in r_groups:
        r_group_row = [x for x in r_group_list if x.find(r) > -1]
        r_group_summary.append(list(enumerate(r_group_row)))
    return used, r_group_summary


def build_offset_list(r_group_summary: list) -> Tuple[int, list]:
    """
    Build a list of R-group offsets, for instance if we have 3*R1, 4*R2, 3*R3 and want to capture where
    each group starts, our offsets would be [0,3,6]
    @param r_group_summary: summary generated by parse_rgroups
    @return: number of R-groups, list of offsets
    """
    # create a list of offsets for enumerating R-groups
    num_subst = [len(x) for x in r_group_summary]
    num_r_groups = len(num_subst)
    offset_list = [0]
    for n in range(1, len(num_subst)):
        offset_list.append(sum(num_subst[:n]))
    return num_r_groups, offset_list


def build_output_list(core_smiles: str, used: dict, r_group_summary: list, vector_size: int, offset_list: list) -> List[
    list]:
    """
    Reassemble the core and R-groups
    @param core_smiles: SMILES for the core
    @param used: Dictionary of SMILES for molecules that have already been sythesized
    @param r_group_summary: summary generated by parse_rgroups
    @param vector_size:
    @param offset_list: list of offsets generated by build_offset_list
    @return: list of molecules and R-groups that have not been synthesized
    """
    output_list = []
    num_subst = [len(x) for x in r_group_summary]
    num_products = np.prod(num_subst)
    for row in tqdm(product(*r_group_summary), total=num_products):
        # name_str = ".".join([x[1] for x in row])
        row_vec = np.zeros(vector_size, dtype=np.int)
        for [idx, rg], offset in zip(row, offset_list):
            row_vec[idx + offset] = 1
        test_str = ",".join(map(str, row_vec))
        if test_str not in used:
            fragment_smiles = ".".join([core_smiles] + [x[1] for x in row])
            output_mol = Chem.MolFromSmiles(fragment_smiles)
            output_mol = weld_r_groups(output_mol)
            output_smiles = Chem.MolToSmiles(output_mol)
            output_list.append([output_smiles] + [x[1] for x in row] + list(row_vec))
    return output_list


def write_output(lm, df, num_r_groups, output_list, prefix):
    """
    Write the output file
    @param lm: linear model that was read from disc
    @param df: data frame with R-groups
    @param num_r_groups: number of R-groups
    @param output_list: list produced by build_output_list
    @param prefix: prefix for output file names
    @return: nothing
    """
    output_df = pd.DataFrame(output_list)
    r_group_names = ["SMILES"]+["R%d_SMILES" % (i + 1) for i in range(0, num_r_groups)]
    col_names = r_group_names + (list(df.columns)[1:])
    output_df.columns = col_names
    pred = lm.predict(output_df.values[0::, num_r_groups+1::])
    output_df['Pred'] = pred
    final_df = output_df[r_group_names + ['Pred']]
    not_synthesized_csv = prefix + "_not_synthesized.csv"
    print("wrote", not_synthesized_csv)
    final_df.to_csv(not_synthesized_csv, index=False, float_format="%.2f")


def free_wilson_enumeration(core_file_name, model_file_name, vector_file_name, prefix):
    """
    Driver function - enumerate products from core + R-groups
    @param core_file_name: core molfile name
    @param model_file_name: file name with pickled model
    @param vector_file_name: file with R-group descriptors
    @param prefix: prefix for output
    @return: Nothing
    """
    core_mol = Chem.MolFromMolFile(core_file_name)
    reflect_rgroups(core_mol)
    core_smiles = Chem.MolToSmiles(core_mol)
    pyfancy.pyfancy().red().bold().add("Enumerating New Products").output()
    lm, df = read_input(model_file_name, vector_file_name)
    num_row, num_cols = df.shape
    vector_size = num_cols - 1
    used, r_group_summary = parse_rgroups(df)
    num_r_groups, offset_list = build_offset_list(r_group_summary)
    # Handle the case where only 1 R-group is provided
    if num_r_groups > 1:
        output_list = build_output_list(core_smiles, used, r_group_summary, vector_size, offset_list)
        print("Generated %d products" % len(output_list))
        if len(output_list) > 0:
            write_output(lm, df, num_r_groups, output_list, prefix)
    else:
        print("only 1 R-group, no additional products possible")


if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("usage: %s model_file vector_file prefix" % (sys.argv[0]))
        sys.exit(0)
    free_wilson_enumeration(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])
